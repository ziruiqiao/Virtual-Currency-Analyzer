{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-30T22:32:00.371917500Z",
     "start_time": "2023-06-30T22:32:00.350915900Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from mike_config import TFrame, crypto_lst, time_frame\n",
    "\n",
    "sys.path.append(r\"D:\\GitHub\\tryStock\\model\\util\")\n",
    "import plot_utils\n",
    "from plot_utils import one_hot, plot_curve\n",
    "\n",
    "INPUT_LEN = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import featuretools as ft\n",
    "\n",
    "def get_data(symbol: str, time_frame: str):\n",
    "    file_path = 'D:/GitHub/tryStock/data/' + symbol.replace(\"/\", \"\") + '/' + time_frame + '/featured.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "data = get_data(crypto_lst[0], time_frame[0].name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-30T22:26:34.344726500Z",
     "start_time": "2023-06-30T22:26:20.925302100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "           open0     high0      low0    close0     volume0     open1  \\\n0        9343.99   9345.00   9335.00   9342.00   39.174849   9342.00   \n1       16919.70  16927.53  16915.76  16925.78  602.397270  16925.55   \n2       22823.50  22847.75  22819.79  22843.44  207.684440  22843.44   \n3       63158.74  63326.80  63158.73  63221.87  225.971895  63221.86   \n4        8846.08   8858.50   8846.08   8854.00  152.264200   8854.06   \n...          ...       ...       ...       ...         ...       ...   \n571423   3527.85   3528.90   3523.12   3525.21   92.071247   3525.10   \n571424   9610.03   9621.73   9607.28   9621.40   86.042948   9620.88   \n571425  35848.20  35886.88  35788.25  35822.33  425.228634  35822.33   \n571426   5058.78   5072.16   5057.61   5070.37   92.217737   5068.73   \n571427   3821.49   3824.18   3820.39   3824.18   65.174364   3824.01   \n\n           high1      low1    close1     volume1  ...    high28     low28  \\\n0        9344.00   9336.08   9340.17   57.982222  ...   9450.00   9414.48   \n1       16939.00  16915.00  16932.84  995.653940  ...  17008.40  16991.91   \n2       22875.00  22830.67  22835.89  485.292770  ...  22780.00  22720.00   \n3       63246.25  63066.06  63072.28  156.609650  ...  63061.81  62851.09   \n4        8860.68   8848.78   8859.62  134.643439  ...   8844.92   8835.97   \n...          ...       ...       ...         ...  ...       ...       ...   \n571423   3527.22   3523.05   3524.02   50.470263  ...   3534.80   3530.00   \n571424   9621.55   9610.25   9616.83   93.361273  ...   9601.86   9594.62   \n571425  35914.93  35724.72  35888.09  529.474273  ...  36334.75  36223.90   \n571426   5075.33   5068.73   5073.35   67.870803  ...   5141.25   5125.46   \n571427   3825.00   3822.67   3823.62   25.569727  ...   3829.94   3826.90   \n\n         close28     volume28    open29    high29     low29   close29  \\\n0        9435.01   147.591771   9435.57   9446.07   9421.68   9433.72   \n1       16993.73  1239.900520  16994.12  16998.66  16990.34  16993.61   \n2       22760.03   250.154060  22760.03  22783.00  22735.51  22751.83   \n3       63056.19   292.155324  63056.20  63211.70  63053.41  63203.59   \n4        8838.63   109.258707   8838.63   8848.82   8838.41   8843.91   \n...          ...          ...       ...       ...       ...       ...   \n571423   3532.84    63.102864   3532.80   3535.00   3531.97   3534.27   \n571424   9601.35    57.199037   9601.35   9633.11   9601.35   9628.19   \n571425  36304.99   205.225930  36306.12  36366.15  36260.08  36285.08   \n571426   5132.41    97.197409   5131.30   5137.91   5123.30   5136.99   \n571427   3827.17    75.740783   3827.21   3833.44   3827.17   3830.59   \n\n          volume29  prediction  \n0       111.563262           2  \n1       620.108180           2  \n2       213.239800           1  \n3       414.004724           1  \n4       117.590723           2  \n...            ...         ...  \n571423   29.698826           1  \n571424  324.035131           2  \n571425  201.508566           1  \n571426  160.715247           1  \n571427  179.293633           2  \n\n[571428 rows x 151 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open0</th>\n      <th>high0</th>\n      <th>low0</th>\n      <th>close0</th>\n      <th>volume0</th>\n      <th>open1</th>\n      <th>high1</th>\n      <th>low1</th>\n      <th>close1</th>\n      <th>volume1</th>\n      <th>...</th>\n      <th>high28</th>\n      <th>low28</th>\n      <th>close28</th>\n      <th>volume28</th>\n      <th>open29</th>\n      <th>high29</th>\n      <th>low29</th>\n      <th>close29</th>\n      <th>volume29</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9343.99</td>\n      <td>9345.00</td>\n      <td>9335.00</td>\n      <td>9342.00</td>\n      <td>39.174849</td>\n      <td>9342.00</td>\n      <td>9344.00</td>\n      <td>9336.08</td>\n      <td>9340.17</td>\n      <td>57.982222</td>\n      <td>...</td>\n      <td>9450.00</td>\n      <td>9414.48</td>\n      <td>9435.01</td>\n      <td>147.591771</td>\n      <td>9435.57</td>\n      <td>9446.07</td>\n      <td>9421.68</td>\n      <td>9433.72</td>\n      <td>111.563262</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16919.70</td>\n      <td>16927.53</td>\n      <td>16915.76</td>\n      <td>16925.78</td>\n      <td>602.397270</td>\n      <td>16925.55</td>\n      <td>16939.00</td>\n      <td>16915.00</td>\n      <td>16932.84</td>\n      <td>995.653940</td>\n      <td>...</td>\n      <td>17008.40</td>\n      <td>16991.91</td>\n      <td>16993.73</td>\n      <td>1239.900520</td>\n      <td>16994.12</td>\n      <td>16998.66</td>\n      <td>16990.34</td>\n      <td>16993.61</td>\n      <td>620.108180</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22823.50</td>\n      <td>22847.75</td>\n      <td>22819.79</td>\n      <td>22843.44</td>\n      <td>207.684440</td>\n      <td>22843.44</td>\n      <td>22875.00</td>\n      <td>22830.67</td>\n      <td>22835.89</td>\n      <td>485.292770</td>\n      <td>...</td>\n      <td>22780.00</td>\n      <td>22720.00</td>\n      <td>22760.03</td>\n      <td>250.154060</td>\n      <td>22760.03</td>\n      <td>22783.00</td>\n      <td>22735.51</td>\n      <td>22751.83</td>\n      <td>213.239800</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>63158.74</td>\n      <td>63326.80</td>\n      <td>63158.73</td>\n      <td>63221.87</td>\n      <td>225.971895</td>\n      <td>63221.86</td>\n      <td>63246.25</td>\n      <td>63066.06</td>\n      <td>63072.28</td>\n      <td>156.609650</td>\n      <td>...</td>\n      <td>63061.81</td>\n      <td>62851.09</td>\n      <td>63056.19</td>\n      <td>292.155324</td>\n      <td>63056.20</td>\n      <td>63211.70</td>\n      <td>63053.41</td>\n      <td>63203.59</td>\n      <td>414.004724</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8846.08</td>\n      <td>8858.50</td>\n      <td>8846.08</td>\n      <td>8854.00</td>\n      <td>152.264200</td>\n      <td>8854.06</td>\n      <td>8860.68</td>\n      <td>8848.78</td>\n      <td>8859.62</td>\n      <td>134.643439</td>\n      <td>...</td>\n      <td>8844.92</td>\n      <td>8835.97</td>\n      <td>8838.63</td>\n      <td>109.258707</td>\n      <td>8838.63</td>\n      <td>8848.82</td>\n      <td>8838.41</td>\n      <td>8843.91</td>\n      <td>117.590723</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>571423</th>\n      <td>3527.85</td>\n      <td>3528.90</td>\n      <td>3523.12</td>\n      <td>3525.21</td>\n      <td>92.071247</td>\n      <td>3525.10</td>\n      <td>3527.22</td>\n      <td>3523.05</td>\n      <td>3524.02</td>\n      <td>50.470263</td>\n      <td>...</td>\n      <td>3534.80</td>\n      <td>3530.00</td>\n      <td>3532.84</td>\n      <td>63.102864</td>\n      <td>3532.80</td>\n      <td>3535.00</td>\n      <td>3531.97</td>\n      <td>3534.27</td>\n      <td>29.698826</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>571424</th>\n      <td>9610.03</td>\n      <td>9621.73</td>\n      <td>9607.28</td>\n      <td>9621.40</td>\n      <td>86.042948</td>\n      <td>9620.88</td>\n      <td>9621.55</td>\n      <td>9610.25</td>\n      <td>9616.83</td>\n      <td>93.361273</td>\n      <td>...</td>\n      <td>9601.86</td>\n      <td>9594.62</td>\n      <td>9601.35</td>\n      <td>57.199037</td>\n      <td>9601.35</td>\n      <td>9633.11</td>\n      <td>9601.35</td>\n      <td>9628.19</td>\n      <td>324.035131</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>571425</th>\n      <td>35848.20</td>\n      <td>35886.88</td>\n      <td>35788.25</td>\n      <td>35822.33</td>\n      <td>425.228634</td>\n      <td>35822.33</td>\n      <td>35914.93</td>\n      <td>35724.72</td>\n      <td>35888.09</td>\n      <td>529.474273</td>\n      <td>...</td>\n      <td>36334.75</td>\n      <td>36223.90</td>\n      <td>36304.99</td>\n      <td>205.225930</td>\n      <td>36306.12</td>\n      <td>36366.15</td>\n      <td>36260.08</td>\n      <td>36285.08</td>\n      <td>201.508566</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>571426</th>\n      <td>5058.78</td>\n      <td>5072.16</td>\n      <td>5057.61</td>\n      <td>5070.37</td>\n      <td>92.217737</td>\n      <td>5068.73</td>\n      <td>5075.33</td>\n      <td>5068.73</td>\n      <td>5073.35</td>\n      <td>67.870803</td>\n      <td>...</td>\n      <td>5141.25</td>\n      <td>5125.46</td>\n      <td>5132.41</td>\n      <td>97.197409</td>\n      <td>5131.30</td>\n      <td>5137.91</td>\n      <td>5123.30</td>\n      <td>5136.99</td>\n      <td>160.715247</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>571427</th>\n      <td>3821.49</td>\n      <td>3824.18</td>\n      <td>3820.39</td>\n      <td>3824.18</td>\n      <td>65.174364</td>\n      <td>3824.01</td>\n      <td>3825.00</td>\n      <td>3822.67</td>\n      <td>3823.62</td>\n      <td>25.569727</td>\n      <td>...</td>\n      <td>3829.94</td>\n      <td>3826.90</td>\n      <td>3827.17</td>\n      <td>75.740783</td>\n      <td>3827.21</td>\n      <td>3833.44</td>\n      <td>3827.17</td>\n      <td>3830.59</td>\n      <td>179.293633</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>571428 rows × 151 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = data.drop(data.columns[120:160], axis=1)\n",
    "data1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-30T22:26:34.593740700Z",
     "start_time": "2023-06-30T22:26:34.346729400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "         index     open0     high0      low0    close0     volume0     open1  \\\n0            0   9343.99   9345.00   9335.00   9342.00   39.174849   9342.00   \n1            1  16919.70  16927.53  16915.76  16925.78  602.397270  16925.55   \n2            2  22823.50  22847.75  22819.79  22843.44  207.684440  22843.44   \n3            3  63158.74  63326.80  63158.73  63221.87  225.971895  63221.86   \n4            4   8846.08   8858.50   8846.08   8854.00  152.264200   8854.06   \n...        ...       ...       ...       ...       ...         ...       ...   \n571423  571423   3527.85   3528.90   3523.12   3525.21   92.071247   3525.10   \n571424  571424   9610.03   9621.73   9607.28   9621.40   86.042948   9620.88   \n571425  571425  35848.20  35886.88  35788.25  35822.33  425.228634  35822.33   \n571426  571426   5058.78   5072.16   5057.61   5070.37   92.217737   5068.73   \n571427  571427   3821.49   3824.18   3820.39   3824.18   65.174364   3824.01   \n\n           high1      low1    close1  ...    high28     low28   close28  \\\n0        9344.00   9336.08   9340.17  ...   9450.00   9414.48   9435.01   \n1       16939.00  16915.00  16932.84  ...  17008.40  16991.91  16993.73   \n2       22875.00  22830.67  22835.89  ...  22780.00  22720.00  22760.03   \n3       63246.25  63066.06  63072.28  ...  63061.81  62851.09  63056.19   \n4        8860.68   8848.78   8859.62  ...   8844.92   8835.97   8838.63   \n...          ...       ...       ...  ...       ...       ...       ...   \n571423   3527.22   3523.05   3524.02  ...   3534.80   3530.00   3532.84   \n571424   9621.55   9610.25   9616.83  ...   9601.86   9594.62   9601.35   \n571425  35914.93  35724.72  35888.09  ...  36334.75  36223.90  36304.99   \n571426   5075.33   5068.73   5073.35  ...   5141.25   5125.46   5132.41   \n571427   3825.00   3822.67   3823.62  ...   3829.94   3826.90   3827.17   \n\n           volume28    open29    high29     low29   close29    volume29  \\\n0        147.591771   9435.57   9446.07   9421.68   9433.72  111.563262   \n1       1239.900520  16994.12  16998.66  16990.34  16993.61  620.108180   \n2        250.154060  22760.03  22783.00  22735.51  22751.83  213.239800   \n3        292.155324  63056.20  63211.70  63053.41  63203.59  414.004724   \n4        109.258707   8838.63   8848.82   8838.41   8843.91  117.590723   \n...             ...       ...       ...       ...       ...         ...   \n571423    63.102864   3532.80   3535.00   3531.97   3534.27   29.698826   \n571424    57.199037   9601.35   9633.11   9601.35   9628.19  324.035131   \n571425   205.225930  36306.12  36366.15  36260.08  36285.08  201.508566   \n571426    97.197409   5131.30   5137.91   5123.30   5136.99  160.715247   \n571427    75.740783   3827.21   3833.44   3827.17   3830.59  179.293633   \n\n        prediction  \n0                2  \n1                2  \n2                1  \n3                1  \n4                2  \n...            ...  \n571423           1  \n571424           2  \n571425           1  \n571426           1  \n571427           2  \n\n[571428 rows x 152 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>open0</th>\n      <th>high0</th>\n      <th>low0</th>\n      <th>close0</th>\n      <th>volume0</th>\n      <th>open1</th>\n      <th>high1</th>\n      <th>low1</th>\n      <th>close1</th>\n      <th>...</th>\n      <th>high28</th>\n      <th>low28</th>\n      <th>close28</th>\n      <th>volume28</th>\n      <th>open29</th>\n      <th>high29</th>\n      <th>low29</th>\n      <th>close29</th>\n      <th>volume29</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>9343.99</td>\n      <td>9345.00</td>\n      <td>9335.00</td>\n      <td>9342.00</td>\n      <td>39.174849</td>\n      <td>9342.00</td>\n      <td>9344.00</td>\n      <td>9336.08</td>\n      <td>9340.17</td>\n      <td>...</td>\n      <td>9450.00</td>\n      <td>9414.48</td>\n      <td>9435.01</td>\n      <td>147.591771</td>\n      <td>9435.57</td>\n      <td>9446.07</td>\n      <td>9421.68</td>\n      <td>9433.72</td>\n      <td>111.563262</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>16919.70</td>\n      <td>16927.53</td>\n      <td>16915.76</td>\n      <td>16925.78</td>\n      <td>602.397270</td>\n      <td>16925.55</td>\n      <td>16939.00</td>\n      <td>16915.00</td>\n      <td>16932.84</td>\n      <td>...</td>\n      <td>17008.40</td>\n      <td>16991.91</td>\n      <td>16993.73</td>\n      <td>1239.900520</td>\n      <td>16994.12</td>\n      <td>16998.66</td>\n      <td>16990.34</td>\n      <td>16993.61</td>\n      <td>620.108180</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>22823.50</td>\n      <td>22847.75</td>\n      <td>22819.79</td>\n      <td>22843.44</td>\n      <td>207.684440</td>\n      <td>22843.44</td>\n      <td>22875.00</td>\n      <td>22830.67</td>\n      <td>22835.89</td>\n      <td>...</td>\n      <td>22780.00</td>\n      <td>22720.00</td>\n      <td>22760.03</td>\n      <td>250.154060</td>\n      <td>22760.03</td>\n      <td>22783.00</td>\n      <td>22735.51</td>\n      <td>22751.83</td>\n      <td>213.239800</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>63158.74</td>\n      <td>63326.80</td>\n      <td>63158.73</td>\n      <td>63221.87</td>\n      <td>225.971895</td>\n      <td>63221.86</td>\n      <td>63246.25</td>\n      <td>63066.06</td>\n      <td>63072.28</td>\n      <td>...</td>\n      <td>63061.81</td>\n      <td>62851.09</td>\n      <td>63056.19</td>\n      <td>292.155324</td>\n      <td>63056.20</td>\n      <td>63211.70</td>\n      <td>63053.41</td>\n      <td>63203.59</td>\n      <td>414.004724</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>8846.08</td>\n      <td>8858.50</td>\n      <td>8846.08</td>\n      <td>8854.00</td>\n      <td>152.264200</td>\n      <td>8854.06</td>\n      <td>8860.68</td>\n      <td>8848.78</td>\n      <td>8859.62</td>\n      <td>...</td>\n      <td>8844.92</td>\n      <td>8835.97</td>\n      <td>8838.63</td>\n      <td>109.258707</td>\n      <td>8838.63</td>\n      <td>8848.82</td>\n      <td>8838.41</td>\n      <td>8843.91</td>\n      <td>117.590723</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>571423</th>\n      <td>571423</td>\n      <td>3527.85</td>\n      <td>3528.90</td>\n      <td>3523.12</td>\n      <td>3525.21</td>\n      <td>92.071247</td>\n      <td>3525.10</td>\n      <td>3527.22</td>\n      <td>3523.05</td>\n      <td>3524.02</td>\n      <td>...</td>\n      <td>3534.80</td>\n      <td>3530.00</td>\n      <td>3532.84</td>\n      <td>63.102864</td>\n      <td>3532.80</td>\n      <td>3535.00</td>\n      <td>3531.97</td>\n      <td>3534.27</td>\n      <td>29.698826</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>571424</th>\n      <td>571424</td>\n      <td>9610.03</td>\n      <td>9621.73</td>\n      <td>9607.28</td>\n      <td>9621.40</td>\n      <td>86.042948</td>\n      <td>9620.88</td>\n      <td>9621.55</td>\n      <td>9610.25</td>\n      <td>9616.83</td>\n      <td>...</td>\n      <td>9601.86</td>\n      <td>9594.62</td>\n      <td>9601.35</td>\n      <td>57.199037</td>\n      <td>9601.35</td>\n      <td>9633.11</td>\n      <td>9601.35</td>\n      <td>9628.19</td>\n      <td>324.035131</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>571425</th>\n      <td>571425</td>\n      <td>35848.20</td>\n      <td>35886.88</td>\n      <td>35788.25</td>\n      <td>35822.33</td>\n      <td>425.228634</td>\n      <td>35822.33</td>\n      <td>35914.93</td>\n      <td>35724.72</td>\n      <td>35888.09</td>\n      <td>...</td>\n      <td>36334.75</td>\n      <td>36223.90</td>\n      <td>36304.99</td>\n      <td>205.225930</td>\n      <td>36306.12</td>\n      <td>36366.15</td>\n      <td>36260.08</td>\n      <td>36285.08</td>\n      <td>201.508566</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>571426</th>\n      <td>571426</td>\n      <td>5058.78</td>\n      <td>5072.16</td>\n      <td>5057.61</td>\n      <td>5070.37</td>\n      <td>92.217737</td>\n      <td>5068.73</td>\n      <td>5075.33</td>\n      <td>5068.73</td>\n      <td>5073.35</td>\n      <td>...</td>\n      <td>5141.25</td>\n      <td>5125.46</td>\n      <td>5132.41</td>\n      <td>97.197409</td>\n      <td>5131.30</td>\n      <td>5137.91</td>\n      <td>5123.30</td>\n      <td>5136.99</td>\n      <td>160.715247</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>571427</th>\n      <td>571427</td>\n      <td>3821.49</td>\n      <td>3824.18</td>\n      <td>3820.39</td>\n      <td>3824.18</td>\n      <td>65.174364</td>\n      <td>3824.01</td>\n      <td>3825.00</td>\n      <td>3822.67</td>\n      <td>3823.62</td>\n      <td>...</td>\n      <td>3829.94</td>\n      <td>3826.90</td>\n      <td>3827.17</td>\n      <td>75.740783</td>\n      <td>3827.21</td>\n      <td>3833.44</td>\n      <td>3827.17</td>\n      <td>3830.59</td>\n      <td>179.293633</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>571428 rows × 152 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_arr = np.arange(0, data1.shape[0])\n",
    "data1.insert(0, \"index\", pd.DataFrame(np_arr))\n",
    "data1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-30T22:32:48.539621200Z",
     "start_time": "2023-06-30T22:32:48.402973500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeq\\anaconda3\\lib\\site-packages\\featuretools\\entityset\\entityset.py:754: UserWarning: A Woodwork-initialized DataFrame was provided, so the following parameters were ignored: index\n",
      "  warnings.warn(\n",
      "C:\\Users\\mikeq\\anaconda3\\lib\\site-packages\\featuretools\\synthesis\\deep_feature_synthesis.py:169: UserWarning: Only one dataframe in entityset, changing max_depth to 1 since deeper features cannot be created\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "           open0     high0      low0    close0     volume0     open1  \\\nindex                                                                  \n0        9343.99   9345.00   9335.00   9342.00   39.174849   9342.00   \n1       16919.70  16927.53  16915.76  16925.78  602.397270  16925.55   \n2       22823.50  22847.75  22819.79  22843.44  207.684440  22843.44   \n3       63158.74  63326.80  63158.73  63221.87  225.971895  63221.86   \n4        8846.08   8858.50   8846.08   8854.00  152.264200   8854.06   \n...          ...       ...       ...       ...         ...       ...   \n571423   3527.85   3528.90   3523.12   3525.21   92.071247   3525.10   \n571424   9610.03   9621.73   9607.28   9621.40   86.042948   9620.88   \n571425  35848.20  35886.88  35788.25  35822.33  425.228634  35822.33   \n571426   5058.78   5072.16   5057.61   5070.37   92.217737   5068.73   \n571427   3821.49   3824.18   3820.39   3824.18   65.174364   3824.01   \n\n           high1      low1    close1     volume1  ...    high28     low28  \\\nindex                                             ...                       \n0        9344.00   9336.08   9340.17   57.982222  ...   9450.00   9414.48   \n1       16939.00  16915.00  16932.84  995.653940  ...  17008.40  16991.91   \n2       22875.00  22830.67  22835.89  485.292770  ...  22780.00  22720.00   \n3       63246.25  63066.06  63072.28  156.609650  ...  63061.81  62851.09   \n4        8860.68   8848.78   8859.62  134.643439  ...   8844.92   8835.97   \n...          ...       ...       ...         ...  ...       ...       ...   \n571423   3527.22   3523.05   3524.02   50.470263  ...   3534.80   3530.00   \n571424   9621.55   9610.25   9616.83   93.361273  ...   9601.86   9594.62   \n571425  35914.93  35724.72  35888.09  529.474273  ...  36334.75  36223.90   \n571426   5075.33   5068.73   5073.35   67.870803  ...   5141.25   5125.46   \n571427   3825.00   3822.67   3823.62   25.569727  ...   3829.94   3826.90   \n\n         close28     volume28    open29    high29     low29   close29  \\\nindex                                                                   \n0        9435.01   147.591771   9435.57   9446.07   9421.68   9433.72   \n1       16993.73  1239.900520  16994.12  16998.66  16990.34  16993.61   \n2       22760.03   250.154060  22760.03  22783.00  22735.51  22751.83   \n3       63056.19   292.155324  63056.20  63211.70  63053.41  63203.59   \n4        8838.63   109.258707   8838.63   8848.82   8838.41   8843.91   \n...          ...          ...       ...       ...       ...       ...   \n571423   3532.84    63.102864   3532.80   3535.00   3531.97   3534.27   \n571424   9601.35    57.199037   9601.35   9633.11   9601.35   9628.19   \n571425  36304.99   205.225930  36306.12  36366.15  36260.08  36285.08   \n571426   5132.41    97.197409   5131.30   5137.91   5123.30   5136.99   \n571427   3827.17    75.740783   3827.21   3833.44   3827.17   3830.59   \n\n          volume29  prediction  \nindex                           \n0       111.563262           2  \n1       620.108180           2  \n2       213.239800           1  \n3       414.004724           1  \n4       117.590723           2  \n...            ...         ...  \n571423   29.698826           1  \n571424  324.035131           2  \n571425  201.508566           1  \n571426  160.715247           1  \n571427  179.293633           2  \n\n[571428 rows x 151 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open0</th>\n      <th>high0</th>\n      <th>low0</th>\n      <th>close0</th>\n      <th>volume0</th>\n      <th>open1</th>\n      <th>high1</th>\n      <th>low1</th>\n      <th>close1</th>\n      <th>volume1</th>\n      <th>...</th>\n      <th>high28</th>\n      <th>low28</th>\n      <th>close28</th>\n      <th>volume28</th>\n      <th>open29</th>\n      <th>high29</th>\n      <th>low29</th>\n      <th>close29</th>\n      <th>volume29</th>\n      <th>prediction</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9343.99</td>\n      <td>9345.00</td>\n      <td>9335.00</td>\n      <td>9342.00</td>\n      <td>39.174849</td>\n      <td>9342.00</td>\n      <td>9344.00</td>\n      <td>9336.08</td>\n      <td>9340.17</td>\n      <td>57.982222</td>\n      <td>...</td>\n      <td>9450.00</td>\n      <td>9414.48</td>\n      <td>9435.01</td>\n      <td>147.591771</td>\n      <td>9435.57</td>\n      <td>9446.07</td>\n      <td>9421.68</td>\n      <td>9433.72</td>\n      <td>111.563262</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16919.70</td>\n      <td>16927.53</td>\n      <td>16915.76</td>\n      <td>16925.78</td>\n      <td>602.397270</td>\n      <td>16925.55</td>\n      <td>16939.00</td>\n      <td>16915.00</td>\n      <td>16932.84</td>\n      <td>995.653940</td>\n      <td>...</td>\n      <td>17008.40</td>\n      <td>16991.91</td>\n      <td>16993.73</td>\n      <td>1239.900520</td>\n      <td>16994.12</td>\n      <td>16998.66</td>\n      <td>16990.34</td>\n      <td>16993.61</td>\n      <td>620.108180</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22823.50</td>\n      <td>22847.75</td>\n      <td>22819.79</td>\n      <td>22843.44</td>\n      <td>207.684440</td>\n      <td>22843.44</td>\n      <td>22875.00</td>\n      <td>22830.67</td>\n      <td>22835.89</td>\n      <td>485.292770</td>\n      <td>...</td>\n      <td>22780.00</td>\n      <td>22720.00</td>\n      <td>22760.03</td>\n      <td>250.154060</td>\n      <td>22760.03</td>\n      <td>22783.00</td>\n      <td>22735.51</td>\n      <td>22751.83</td>\n      <td>213.239800</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>63158.74</td>\n      <td>63326.80</td>\n      <td>63158.73</td>\n      <td>63221.87</td>\n      <td>225.971895</td>\n      <td>63221.86</td>\n      <td>63246.25</td>\n      <td>63066.06</td>\n      <td>63072.28</td>\n      <td>156.609650</td>\n      <td>...</td>\n      <td>63061.81</td>\n      <td>62851.09</td>\n      <td>63056.19</td>\n      <td>292.155324</td>\n      <td>63056.20</td>\n      <td>63211.70</td>\n      <td>63053.41</td>\n      <td>63203.59</td>\n      <td>414.004724</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8846.08</td>\n      <td>8858.50</td>\n      <td>8846.08</td>\n      <td>8854.00</td>\n      <td>152.264200</td>\n      <td>8854.06</td>\n      <td>8860.68</td>\n      <td>8848.78</td>\n      <td>8859.62</td>\n      <td>134.643439</td>\n      <td>...</td>\n      <td>8844.92</td>\n      <td>8835.97</td>\n      <td>8838.63</td>\n      <td>109.258707</td>\n      <td>8838.63</td>\n      <td>8848.82</td>\n      <td>8838.41</td>\n      <td>8843.91</td>\n      <td>117.590723</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>571423</th>\n      <td>3527.85</td>\n      <td>3528.90</td>\n      <td>3523.12</td>\n      <td>3525.21</td>\n      <td>92.071247</td>\n      <td>3525.10</td>\n      <td>3527.22</td>\n      <td>3523.05</td>\n      <td>3524.02</td>\n      <td>50.470263</td>\n      <td>...</td>\n      <td>3534.80</td>\n      <td>3530.00</td>\n      <td>3532.84</td>\n      <td>63.102864</td>\n      <td>3532.80</td>\n      <td>3535.00</td>\n      <td>3531.97</td>\n      <td>3534.27</td>\n      <td>29.698826</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>571424</th>\n      <td>9610.03</td>\n      <td>9621.73</td>\n      <td>9607.28</td>\n      <td>9621.40</td>\n      <td>86.042948</td>\n      <td>9620.88</td>\n      <td>9621.55</td>\n      <td>9610.25</td>\n      <td>9616.83</td>\n      <td>93.361273</td>\n      <td>...</td>\n      <td>9601.86</td>\n      <td>9594.62</td>\n      <td>9601.35</td>\n      <td>57.199037</td>\n      <td>9601.35</td>\n      <td>9633.11</td>\n      <td>9601.35</td>\n      <td>9628.19</td>\n      <td>324.035131</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>571425</th>\n      <td>35848.20</td>\n      <td>35886.88</td>\n      <td>35788.25</td>\n      <td>35822.33</td>\n      <td>425.228634</td>\n      <td>35822.33</td>\n      <td>35914.93</td>\n      <td>35724.72</td>\n      <td>35888.09</td>\n      <td>529.474273</td>\n      <td>...</td>\n      <td>36334.75</td>\n      <td>36223.90</td>\n      <td>36304.99</td>\n      <td>205.225930</td>\n      <td>36306.12</td>\n      <td>36366.15</td>\n      <td>36260.08</td>\n      <td>36285.08</td>\n      <td>201.508566</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>571426</th>\n      <td>5058.78</td>\n      <td>5072.16</td>\n      <td>5057.61</td>\n      <td>5070.37</td>\n      <td>92.217737</td>\n      <td>5068.73</td>\n      <td>5075.33</td>\n      <td>5068.73</td>\n      <td>5073.35</td>\n      <td>67.870803</td>\n      <td>...</td>\n      <td>5141.25</td>\n      <td>5125.46</td>\n      <td>5132.41</td>\n      <td>97.197409</td>\n      <td>5131.30</td>\n      <td>5137.91</td>\n      <td>5123.30</td>\n      <td>5136.99</td>\n      <td>160.715247</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>571427</th>\n      <td>3821.49</td>\n      <td>3824.18</td>\n      <td>3820.39</td>\n      <td>3824.18</td>\n      <td>65.174364</td>\n      <td>3824.01</td>\n      <td>3825.00</td>\n      <td>3822.67</td>\n      <td>3823.62</td>\n      <td>25.569727</td>\n      <td>...</td>\n      <td>3829.94</td>\n      <td>3826.90</td>\n      <td>3827.17</td>\n      <td>75.740783</td>\n      <td>3827.21</td>\n      <td>3833.44</td>\n      <td>3827.17</td>\n      <td>3830.59</td>\n      <td>179.293633</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>571428 rows × 151 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import featuretools as ft\n",
    "\n",
    "es = ft.EntitySet(id=\"my_set\")\n",
    "es = es.add_dataframe(dataframe_name='my_df', dataframe=data1, index=\"index\")\n",
    "\n",
    "feature_matrix, feature_defs = ft.dfs(entityset=es, target_dataframe_name='my_df')\n",
    "feature_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-30T22:50:24.649343100Z",
     "start_time": "2023-06-30T22:50:10.095092Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(INPUT_LEN, 16)\n",
    "        self.fc2 = nn.Linear(16, 2)\n",
    "        self.fc3 = nn.Linear(2, 1)\n",
    "        # self.fc4 = nn.Linear(32, 16)\n",
    "        # self.fc5 = nn.Linear(16, 8)\n",
    "        # self.fc6 = nn.Linear(8, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # x = F.relu(self.fc3(x))\n",
    "        # x = F.relu(self.fc4(x))\n",
    "        # x = F.relu(self.fc5(x))\n",
    "        x = self.fc3(x)\n",
    "        out = self.sigmoid(x)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T19:08:00.313724100Z",
     "start_time": "2023-06-21T19:08:00.311722600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_dataset(symbol: str, time_frame: str, target: int, batch_size=512):\n",
    "    file_path = 'D:/GitHub/tryStock/data/' + symbol.replace(\"/\", \"\") + '/' + time_frame + '/featured.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    true_df = df[df.iloc[:, -1] == target]\n",
    "    true_df.iloc[:, -1] = 1\n",
    "    other_df = df[df.iloc[:, -1] != target]\n",
    "    false_df = other_df.sample(true_df.shape[0])\n",
    "    false_df.iloc[:, -1] = 0\n",
    "    train_df, test_df = train_test_split(pd.concat([true_df, false_df]), test_size=0.2, random_state=42)\n",
    "    train_inputs = torch.tensor(train_df.iloc[:, :INPUT_LEN].values)\n",
    "    train_outputs = torch.tensor(train_df.iloc[:, -1].values).float()\n",
    "    test_inputs = torch.tensor(test_df.iloc[:, :INPUT_LEN].values)\n",
    "    test_outputs = torch.tensor(test_df.iloc[:, -1].values).float()\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(train_inputs, train_outputs), batch_size=batch_size,  shuffle=True)\n",
    "    test_loader = DataLoader(TensorDataset(test_inputs, test_outputs), batch_size=batch_size,  shuffle=True)\n",
    "    return train_loader, test_loader\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T19:06:14.519374300Z",
     "start_time": "2023-06-21T19:06:14.501360300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "train_loader3, test_loader3 = load_dataset(crypto_lst[0], time_frame[0].name, 3, 512)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T18:43:04.817640400Z",
     "start_time": "2023-06-21T18:42:51.559070700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def split_data(symbol: str, time_frame: str, target: int):\n",
    "    file_path = 'D:/GitHub/tryStock/data/' + symbol.replace(\"/\", \"\") + '/' + time_frame + '/featured.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    true_df = df[df.iloc[:, -1] == target]\n",
    "    true_df.loc[:, \"prediction\"] = 1\n",
    "    other_df = df[df.iloc[:, -1] != target]\n",
    "    false_df = other_df.sample(true_df.shape[0])\n",
    "    false_df.loc[:, \"prediction\"] = 0\n",
    "    train_df, test_df = train_test_split(pd.concat([true_df, false_df]), test_size=0.2, random_state=42)\n",
    "    train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    return train_df.iloc[:, :INPUT_LEN], train_df.iloc[:, -1], test_df.iloc[:, :INPUT_LEN], test_df.iloc[:, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T19:27:34.781734700Z",
     "start_time": "2023-06-21T19:27:34.771717300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def logistic_train(target: int):\n",
    "    x_train, y_train, x_test, y_test = split_data(crypto_lst[0], time_frame[0].name, 3)\n",
    "    # Initialize the logistic regression model\n",
    "    model = LogisticRegression(max_iter=99999)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Current Target:\", target)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "for i in range(4):\n",
    "    logistic_train(i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def split_data2(symbol: str, time_frame: str):\n",
    "    file_path = 'D:/GitHub/tryStock/data/' + symbol.replace(\"/\", \"\") + '/' + time_frame + '/featured.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    x_train = train_df.iloc[:, :INPUT_LEN]\n",
    "    y_train = train_df.iloc[:, -1]\n",
    "    x_test = test_df.iloc[:, :INPUT_LEN]\n",
    "    y_test = test_df.iloc[:, -1]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_test, y_test = split_data2(crypto_lst[0], time_frame[0].name)\n",
    "\n",
    "\n",
    "def rf_train():\n",
    "    model = RandomForestClassifier(n_estimators=500, class_weight='balanced_subsample', max_depth=10, min_samples_split=2, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T22:28:59.319985800Z",
     "start_time": "2023-06-21T22:28:46.602070100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43749890625273435\n"
     ]
    }
   ],
   "source": [
    "rf_train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T23:12:21.126503200Z",
     "start_time": "2023-06-21T22:28:59.321986200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[36], line 25\u001B[0m\n\u001B[0;32m     23\u001B[0m     confusion_mat \u001B[38;5;241m=\u001B[39m confusion_matrix(true_labels, predicted_labels)\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfusion matrix: \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mconfusion_mat\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 25\u001B[0m test(net, \u001B[43mtest_loader\u001B[49m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def test(net, test_loader):\n",
    "    total_correct = [0, 0, 0, 0]\n",
    "    total_count = [0, 0, 0, 0]\n",
    "    true_labels = np.array([])\n",
    "    predicted_labels = np.array([])\n",
    "    for value, label in test_loader:\n",
    "        value = value.view(value.size(0), INPUT_LEN)\n",
    "        out = net(value)\n",
    "        norm_out = normalize(out, p=2.0, dim=1)\n",
    "        scaled_tensor = (norm_out - norm_out.min()) / (norm_out.max() - norm_out.min())\n",
    "        pred = scaled_tensor.argmax(dim=1)\n",
    "        temp = pred.eq(label) #.sum().float()\n",
    "\n",
    "        print(confusion_matrix(label.numpy(), pred.numpy()))\n",
    "\n",
    "        true_labels = np.append(true_labels, label.numpy())\n",
    "        predicted_labels = np.append(predicted_labels, pred.numpy())\n",
    "\n",
    "\n",
    "    confusion_mat = confusion_matrix(true_labels, predicted_labels)\n",
    "    print(f\"confusion matrix: \\n{confusion_mat}\")\n",
    "test(net, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T18:48:27.973611Z",
     "start_time": "2023-06-21T18:48:27.920614100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
